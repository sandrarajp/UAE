# -*- coding: utf-8 -*-
"""SME Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15jdM3Ho4ezK8T1ptYuP8vKAdsx_0X_8b
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

sme   = pd.read_csv("sme_profiles.csv")
kpis  = pd.read_csv("monthly_kpis.csv", parse_dates=["month"])
macro = pd.read_csv("macro_indicators_uae_monthly.csv", parse_dates=["month"])

print(sme.head())
print(kpis.head())
print(macro.head())

# SMEs
print("SME Dataset Info:")
print(sme.info())
print("\nMissing values:\n", sme.isnull().sum())
print("Duplicates:", sme.duplicated().sum())

# KPIs
print("\nKPI Dataset Info:")
print(kpis.info())
print("\nMissing values:\n", kpis.isnull().sum())
print("Duplicates:", kpis.duplicated().sum())

# Macro Indicators
print("\nMacro Dataset Info:")
print(macro.info())
print("\nMissing values:\n", macro.isnull().sum())
print("Duplicates:", macro.duplicated().sum())

import pandas as pd

def clean_dataframe(df, date_cols=None, category_cols=None):
    df = df.copy()

    # 1. Handle missing values
    for col in df.select_dtypes(include="number").columns:
        df[col] = df[col].fillna(df[col].median())
    for col in df.select_dtypes(include="object").columns:
        df[col] = df[col].fillna(df[col].mode()[0])

    # 2. Ensure numeric columns are numeric
    for col in df.columns:
        if df[col].dtype == "object":
            try:
                df[col] = pd.to_numeric(df[col])
            except:
                pass  # keep as string if not convertible

    # 3. Standardize categorical columns
    if category_cols:
        for col in category_cols:
            if col in df.columns:
                df[col] = df[col].str.strip().str.lower()

    # 4. Convert date columns
    if date_cols:
        for col in date_cols:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors="coerce")

    # 5. Remove duplicates
    df = df.drop_duplicates()

    return df

sme = clean_dataframe(
    sme,
    category_cols=["industry", "emirate", "license_type"]  # adjust to actual names
)

kpis = clean_dataframe(
    kpis,
    date_cols=["month"],
    category_cols=["kpi_type"]  # adjust if available
)

macro = clean_dataframe(
    macro,
    date_cols=["month"],
    category_cols=["indicator"]  # adjust if available
)

# Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# (Assuming you already have these loaded & cleaned)
# sme = pd.read_csv("cleaned_sme_profiles.csv")
# kpis = pd.read_csv("cleaned_monthly_kpis.csv")
# macro = pd.read_csv("cleaned_macro_indicators_uae_monthly.csv")

# 1. Overview of datasets
print("SME Profiles:\n", sme.head())
print("\nKPIs:\n", kpis.head())
print("\nMacro Indicators:\n", macro.head())

# Industry Distribution
plt.figure(figsize=(10,6))
sns.countplot(data=sme, x="industry", order=sme["industry"].value_counts().index)
plt.xticks(rotation=45)
plt.title("Distribution of SMEs by Industry")
plt.show()

# Emirates Distribution
plt.figure(figsize=(8,5))
sns.countplot(data=sme, x="emirate", order=sme["emirate"].value_counts().index)
plt.title("SMEs by Emirate")
plt.show()

# Revenue Trend
plt.figure(figsize=(12,6))
sns.lineplot(data=kpis, x="month", y="revenue_aed", errorbar=None)  # updated column
plt.title("Monthly SME Revenue Trend")
plt.xlabel("Month")
plt.ylabel("Revenue (AED)")
plt.show()

# Employees vs Revenue
plt.figure(figsize=(10,6))
sns.scatterplot(data=kpis, x="staff_count", y="revenue_aed")  # updated columns
plt.title("Employees vs Revenue")
plt.xlabel("Number of Employees")
plt.ylabel("Revenue (AED)")
plt.show()

# Correlation Heatmap (numeric columns only)
plt.figure(figsize=(10,6))
sns.heatmap(kpis.select_dtypes(include="number").corr(), annot=True, cmap="coolwarm")
plt.title("Correlation Heatmap of SME KPIs")
plt.show()

print(merged.columns)

sme.to_csv("sme_cleaned.csv", index=False)
kpis.to_csv("kpis_cleaned.csv", index=False)
macro.to_csv("macro_cleaned.csv", index=False)

import pandas as pd

sme = pd.read_csv("sme_cleaned.csv")
kpis = pd.read_csv("kpis_cleaned.csv")
macro = pd.read_csv("macro_cleaned.csv")

print("SME Columns:", sme.columns.tolist())
print("KPIs Columns:", kpis.columns.tolist())
print("Macro Columns:", macro.columns.tolist())

merged = pd.merge(kpis, macro, on="month", how="inner")
print("Merged Columns:", merged.columns.tolist())
print(merged.head())

import matplotlib.pyplot as plt
import seaborn as sns

# Revenue vs Economic Activity (PMI)
if "revenue_aed" in merged.columns and "non_oil_pmi" in merged.columns:
    plt.figure(figsize=(12,6))
    sns.lineplot(data=merged, x="month", y="revenue_aed", label="SME Revenue (AED)")
    sns.lineplot(data=merged, x="month", y="non_oil_pmi", label="Non-Oil PMI (GDP Proxy)")
    plt.title("SME Revenue vs UAE Economic Activity (PMI)")
    plt.xticks(rotation=45)
    plt.legend()
    plt.show()
else:
    print("Check column names! 'revenue_aed' or 'non_oil_pmi' not found.")

# Correlation between revenue and PMI (GDP proxy)
corr = merged["revenue_aed"].corr(merged["non_oil_pmi"])
print(f"Correlation between SME Revenue and GDP Proxy (PMI): {corr:.2f}")

# Flag months where revenue is above median but PMI is below median
high_rev_low_gdp = merged[
    (merged["revenue_aed"] > merged["revenue_aed"].median()) &
    (merged["non_oil_pmi"] < merged["non_oil_pmi"].median())
]

print("Months with high SME revenue but low GDP activity (PMI):")
print(high_rev_low_gdp[["month", "revenue_aed", "non_oil_pmi"]])

corr_staff = merged["revenue_aed"].corr(merged["staff_count"])
print(f"Correlation between Revenue and Staff Count: {corr_staff:.2f}")

corr_orders = merged["revenue_aed"].corr(merged["orders"])
print(f"Correlation between Revenue and Orders: {corr_orders:.2f}")

corr_churn = merged["revenue_aed"].corr(merged["churn_rate"])
print(f"Correlation between Revenue and Churn Rate: {corr_churn:.2f}")

merged["marketing_lag1"] = merged["marketing_spend_aed"].shift(1)
print(merged[["month","revenue_aed","marketing_spend_aed","marketing_lag1"]].head())

import matplotlib.pyplot as plt
import seaborn as sns

# 1. Correlation Heatmap
plt.figure(figsize=(10,6))
sns.heatmap(
    merged[["revenue_aed","orders","staff_count","churn_rate","marketing_spend_aed","non_oil_pmi"]].corr(),
    annot=True, cmap="coolwarm", vmin=-1, vmax=1
)
plt.title("Correlation Heatmap: SME Revenue vs KPIs & Economy")
plt.show()

# 2. Revenue vs Orders (Scatter)
plt.figure(figsize=(8,6))
sns.scatterplot(data=merged, x="orders", y="revenue_aed", hue="month", palette="viridis")
plt.title("Orders vs Revenue (colored by Month)")
plt.xlabel("Orders")
plt.ylabel("Revenue (AED)")
plt.xticks(rotation=45)
plt.show()

# 3. Revenue vs Churn Rate (Scatter)
plt.figure(figsize=(8,6))
sns.scatterplot(data=merged, x="churn_rate", y="revenue_aed", color="red")
plt.title("Churn Rate vs Revenue")
plt.xlabel("Churn Rate")
plt.ylabel("Revenue (AED)")
plt.show()

# 4. Revenue & Staff over Time (Line Plot)
plt.figure(figsize=(12,6))
sns.lineplot(data=merged, x="month", y="revenue_aed", label="Revenue (AED)", color="blue")
sns.lineplot(data=merged, x="month", y="staff_count", label="Staff Count", color="orange")
plt.title("Revenue & Staff Over Time")
plt.xticks(rotation=45)
plt.legend()
plt.show()

# 5. Revenue vs Marketing Spend (Scatter)
plt.figure(figsize=(8,6))
sns.scatterplot(data=merged, x="marketing_spend_aed", y="revenue_aed", hue="month", palette="coolwarm")
plt.title("Marketing Spend vs Revenue")
plt.xlabel("Marketing Spend (AED)")
plt.ylabel("Revenue (AED)")
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# Features and target
X = merged[["orders", "churn_rate", "staff_count", "marketing_spend_aed", "non_oil_pmi"]]
y = merged["revenue_aed"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model
model = LinearRegression()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluation
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("RÂ² Score:", r2)
print("MAE:", mae)
print("RMSE:", rmse)

# Feature importance (coefficients)
coefficients = pd.DataFrame({
    "Feature": X.columns,
    "Coefficient": model.coef_
}).sort_values(by="Coefficient", ascending=False)

print(coefficients)

# =========================
# Smart Insights: Revenue Prediction Visualization
# =========================

# Step 1: Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor

# Step 2: Example dataset
# Replace this with your actual dataset
data = pd.DataFrame({
    'Revenue': [100, 150, 200, 250, 300],
    'Marketing_Spend': [50, 60, 70, 80, 90],
    'Orders': [20, 25, 30, 35, 40],
    'Staff_Count': [5, 6, 7, 8, 9]
})

# Step 3: Prepare features and target
X = data[['Marketing_Spend', 'Orders', 'Staff_Count']]
y = data['Revenue']

# Step 4: Train ML model on entire dataset (since small example)
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X, y)

# Step 5: Make predictions for all rows
y_pred = model.predict(X)

# Step 6: Save results to CSV
results = X.copy()
results['Actual_Revenue'] = y.values
results['Predicted_Revenue'] = y_pred
results.to_csv("SME_Revenue_Predictions.csv", index=False)

# Step 7: Plot Actual vs Predicted Revenue
plt.figure(figsize=(8,5))
sns.scatterplot(x=results['Actual_Revenue'], y=results['Predicted_Revenue'], color='blue', s=100)
plt.plot([min(results['Actual_Revenue']), max(results['Actual_Revenue'])],
         [min(results['Actual_Revenue']), max(results['Actual_Revenue'])],
         color='red', linestyle='--')  # ideal line
plt.xlabel("Actual Revenue")
plt.ylabel("Predicted Revenue")
plt.title("Actual vs Predicted Revenue")
plt.show()

# Step 8: Feature Importance
importances = model.feature_importances_
feature_names = X.columns

plt.figure(figsize=(8,5))
sns.barplot(x=importances, y=feature_names, palette='viridis')
plt.title("Feature Importance in Revenue Prediction")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.show()

# =========================
# End of Script
# =========================

import sqlite3
import pandas as pd

# Example Python data
results = pd.DataFrame({
    'Month': ['2025-01', '2025-02', '2025-03'],
    'Actual_Revenue': [100000, 150000, 200000],
    'Predicted_Revenue': [110000, 145000, 210000]
})

feature_df = pd.DataFrame({
    'Feature': ['Marketing_Spend', 'Orders', 'Staff_Count'],
    'Importance': [0.5, 0.3, 0.2]
})

# Connect to SQLite database (creates file if not exists)
conn = sqlite3.connect("SME_Analytics.sqlite")

# Save results to SQL tables
results.to_sql('SME_Revenue_Predictions', con=conn, if_exists='replace', index=False)
feature_df.to_sql('Feature_Importance', con=conn, if_exists='replace', index=False)

# Query all predictions
df_predictions = pd.read_sql("SELECT * FROM SME_Revenue_Predictions", conn)
print(df_predictions)

# Query months where predicted revenue > 200000
high_revenue = pd.read_sql(
    "SELECT Month, Predicted_Revenue FROM SME_Revenue_Predictions WHERE Predicted_Revenue > 200000",
    conn
)
print(high_revenue)

# Query top feature by importance
top_feature = pd.read_sql(
    "SELECT Feature, Importance FROM Feature_Importance ORDER BY Importance DESC LIMIT 1",
    conn
)
print(top_feature)

comparison = pd.read_sql(
    "SELECT Month, Actual_Revenue, Predicted_Revenue, "
    "(Predicted_Revenue - Actual_Revenue) AS Difference "
    "FROM SME_Revenue_Predictions",
    conn
)
print(comparison)

total_predicted = pd.read_sql(
    "SELECT SUM(Predicted_Revenue) AS Total_Predicted_Revenue FROM SME_Revenue_Predictions",
    conn
)
print(total_predicted)

import pandas as pd

# Query predictions
df_predictions = pd.read_sql("SELECT * FROM SME_Revenue_Predictions", conn)
print(df_predictions)

# Query feature importance
df_features = pd.read_sql("SELECT * FROM Feature_Importance", conn)
print(df_features)

from google.colab import files

# Download predictions
files.download("SME_Revenue_Predictions.xlsx")

# Download feature importance
files.download("Feature_Importance.xlsx")

from google.colab import files

# Download SQLite database
files.download("SME_Analytics.sqlite")